{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\n\nimport warnings\n\nfrom IPython.display import HTML\n\n## General imports \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\n\n## Torch library\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\n## Sklearn ilbrary\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n\n## Transformers library\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom transformers import AdamW, get_scheduler\n\n\nimport re\nfrom collections import Counter\n\nfrom tqdm.auto import tqdm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-04T07:33:33.268223Z","iopub.execute_input":"2024-07-04T07:33:33.268870Z","iopub.status.idle":"2024-07-04T07:33:49.881660Z","shell.execute_reply.started":"2024-07-04T07:33:33.268839Z","shell.execute_reply":"2024-07-04T07:33:49.880895Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-04 07:33:41.014202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-04 07:33:41.014326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-04 07:33:41.115655: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading the data\n\ndf = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsample_sub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:34:56.861237Z","iopub.execute_input":"2024-07-04T07:34:56.861948Z","iopub.status.idle":"2024-07-04T07:34:56.951224Z","shell.execute_reply.started":"2024-07-04T07:34:56.861903Z","shell.execute_reply":"2024-07-04T07:34:56.950316Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Cleaning ","metadata":{}},{"cell_type":"markdown","source":"Now we need to remove certain text parts. Those parts does not contribute to the overall score and also might confuse the text\n\n - Removing urls\n - Removing HTML tags\n - Removing Emojis\n - Removing punctuations","metadata":{}},{"cell_type":"code","source":"####### Removing urls\ndef remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\n####### Removing HTML tags\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\n####### Removing Emojis\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\n\n####### Removing punctuations\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:35:01.518807Z","iopub.execute_input":"2024-07-04T07:35:01.519884Z","iopub.status.idle":"2024-07-04T07:35:01.526516Z","shell.execute_reply.started":"2024-07-04T07:35:01.519848Z","shell.execute_reply":"2024-07-04T07:35:01.525581Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"##### Performing the function will built on all the text using lambda principal #####\ndf['text']=df['text'].apply(lambda x : remove_URL(x))\ndf['text']=df['text'].apply(lambda x : remove_html(x))\ndf['text']=df['text'].apply(lambda x: remove_emoji(x))\ndf['text']=df['text'].apply(lambda x : remove_punct(x))\n\ntest['text']=test['text'].apply(lambda x : remove_URL(x))\ntest['text']=test['text'].apply(lambda x : remove_html(x))\ntest['text']=test['text'].apply(lambda x: remove_emoji(x))\ntest['text']=test['text'].apply(lambda x : remove_punct(x))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:35:03.144057Z","iopub.execute_input":"2024-07-04T07:35:03.144410Z","iopub.status.idle":"2024-07-04T07:35:03.354039Z","shell.execute_reply.started":"2024-07-04T07:35:03.144384Z","shell.execute_reply":"2024-07-04T07:35:03.353226Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Modeling - Architcture ","metadata":{}},{"cell_type":"code","source":"# Load model directly\n\ntokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:35:54.658887Z","iopub.execute_input":"2024-07-04T07:35:54.659864Z","iopub.status.idle":"2024-07-04T07:36:13.947967Z","shell.execute_reply.started":"2024-07-04T07:35:54.659832Z","shell.execute_reply":"2024-07-04T07:36:13.947059Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43e9719cfe4440669bbbfd137f04c60a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd73747f9ec14c9f8194cf7fda5faa8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4242882b194f32a27324b9f489dde6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0a85427d95744a49840650f830f33d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f17fdde1130545c1a9466dc5f962da09"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1. Tokenize\nThe first step after the preprocessing is to tokenize the data. Tokenization is the process where words are converted into numbers and ids. Each word or part of a word (depend on the tokenizer) are converted into numbers that are readable for the machine\n\nLater we splitting the data into train and validation sets ","metadata":{}},{"cell_type":"code","source":"# Tokenize the train dataset and add target column \ndef tokenize_train(df):\n    \n    tokenized_texts = []\n    \n    # For each text & label we tokenize the text and add the label target into the dictonary\n    for text, label in zip(df[\"text\"], df[\"target\"]):\n        tokenized_text = tokenizer(text, truncation=True)\n        tokenized_text[\"labels\"] = label\n        tokenized_texts.append(tokenized_text)\n        \n    return tokenized_texts\n\n# Tokenize the test dataset \ndef tokenize_test(test):\n    tokenized_texts = []\n    for text in test[\"text\"]:\n          tokenized_texts.append(tokenizer(text, truncation=True))\n    return tokenized_texts\n            \ntokenized_texts = tokenize_train(df)\ntest_texts = tokenize_test(test)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T08:11:55.339496Z","iopub.execute_input":"2024-07-04T08:11:55.339993Z","iopub.status.idle":"2024-07-04T08:11:57.210132Z","shell.execute_reply.started":"2024-07-04T08:11:55.339952Z","shell.execute_reply":"2024-07-04T08:11:57.209329Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the whole text set into train and validation\ntrain_texts, val_texts = train_test_split(tokenized_texts, test_size=0.2, random_state=42)  # Set a seed for reproducibility\n\nprint(len(train_texts))\nprint(len(val_texts))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T08:12:00.494241Z","iopub.execute_input":"2024-07-04T08:12:00.494604Z","iopub.status.idle":"2024-07-04T08:12:00.503049Z","shell.execute_reply.started":"2024-07-04T08:12:00.494575Z","shell.execute_reply":"2024-07-04T08:12:00.502139Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"6090\n1523\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Split to batches ","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n## Set train texts DataLoader\ntrain_dataloader = DataLoader(\n    train_texts, shuffle=True, batch_size=8, collate_fn=data_collator\n)\n\n## Set val texts DataLoader\neval_dataloader = DataLoader(\n    val_texts, batch_size=8, collate_fn=data_collator\n)\n\n## Set test texts DataLoader\ntest_dataloader = DataLoader(\n    test_texts, batch_size=8, collate_fn=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T08:12:02.880779Z","iopub.execute_input":"2024-07-04T08:12:02.881886Z","iopub.status.idle":"2024-07-04T08:12:02.975860Z","shell.execute_reply.started":"2024-07-04T08:12:02.881844Z","shell.execute_reply":"2024-07-04T08:12:02.974953Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"## Small test to see that everything went well with the Dataloader method\nfor batch in train_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2024-07-04T08:12:05.479344Z","iopub.execute_input":"2024-07-04T08:12:05.479724Z","iopub.status.idle":"2024-07-04T08:12:05.488257Z","shell.execute_reply.started":"2024-07-04T08:12:05.479692Z","shell.execute_reply":"2024-07-04T08:12:05.487335Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'input_ids': torch.Size([8, 30]),\n 'attention_mask': torch.Size([8, 30]),\n 'labels': torch.Size([8])}"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3. Train the model","metadata":{}},{"cell_type":"code","source":"# Create optimizer\noptimizer = AdamW(model.parameters(), lr=3e-5)\n\n# Move to GPU to train\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\n# Set epochs numbers, number of training steps and learning rate\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\nprogress_bar = tqdm(range(num_training_steps))\n\n# Train the model\nmodel.train()\nfor epoch in range(num_epochs):\n    # In each batch of the train_dataloader compute \n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:40:54.191285Z","iopub.execute_input":"2024-07-04T07:40:54.192133Z","iopub.status.idle":"2024-07-04T07:42:58.030861Z","shell.execute_reply.started":"2024-07-04T07:40:54.192103Z","shell.execute_reply":"2024-07-04T07:42:58.030122Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2286 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de2b2b2d7d5c45d182beb8b061b7ced5"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluate the model using the validation set\nuse metrics from evaluate library in order to give an estimation ","metadata":{}},{"cell_type":"code","source":"!pip install evaluate\nimport evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmodel.eval()\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:47:38.593460Z","iopub.execute_input":"2024-07-04T07:47:38.594081Z","iopub.status.idle":"2024-07-04T07:47:56.904127Z","shell.execute_reply.started":"2024-07-04T07:47:38.594051Z","shell.execute_reply":"2024-07-04T07:47:56.902987Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ee5296581f9453db0084a45e2fd8c5d"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8365068942875903, 'f1': 0.8043990573448545}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Making the predictions on the test set","metadata":{}},{"cell_type":"code","source":"model.eval()\n    \npredictions = []  # List to store predictions\n\nfor batch in test_dataloader:  \n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n        logits = outputs.logits\n        predictions.extend(torch.argmax(logits, dim=-1).cpu().tolist())  # Append predictions to list","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:15:51.606876Z","iopub.execute_input":"2024-07-04T09:15:51.607783Z","iopub.status.idle":"2024-07-04T09:15:57.122935Z","shell.execute_reply.started":"2024-07-04T09:15:51.607749Z","shell.execute_reply":"2024-07-04T09:15:57.121974Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Insert the predictions into the submission file\nsample_sub[\"target\"] = predictions\nsample_sub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:24:58.360870Z","iopub.execute_input":"2024-07-04T09:24:58.361570Z","iopub.status.idle":"2024-07-04T09:24:58.367552Z","shell.execute_reply.started":"2024-07-04T09:24:58.361539Z","shell.execute_reply":"2024-07-04T09:24:58.366680Z"},"trusted":true},"execution_count":35,"outputs":[]}]}